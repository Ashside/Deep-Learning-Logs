{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "仿射变换中的线性关系是一个很强的假设。它假设输入和输出之间的关系可以用一个线性函数来描述，这在很多实际应用中可能并不成立。\n",
    "\n",
    "有些问题难以通过简单的预处理来解决。例如，图像分类任务中，图像的旋转、缩放、平移等变换可能会导致模型性能下降。对于这些问题，可能需要更复杂的模型来捕捉输入和输出之间的非线性关系。\n",
    "\n",
    "我们可以通过在网络中加入一个或者多个隐藏层来增加模型的复杂度，从而更好地捕捉输入和输出之间的非线性关系。隐藏层可以通过非线性激活函数（如ReLU、sigmoid等）来实现非线性变换。"
   ],
   "id": "6450bec25b3a7f4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RELU\n",
   "id": "35b88441d73ef60a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "x = torch.arange(-8.0, 8.0, 0.1,requires_grad=True)\n",
    "y = torch.relu(x)\n",
    "plt.plot(x.detach().numpy(), y.detach().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ReLU(x)')\n",
    "plt.title('ReLU Activation Function')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 计算ReLU的导数，torch.ones_like(x)作为权重，表示对每个元素都求导，retain_graph=True表示保留计算图，允许后续再次反向传播。常用于可视化激活函数的导数。\n",
    "y.backward(torch.ones_like(x),retain_graph=True)\n",
    "plt.plot(x.detach().numpy(), x.grad.detach().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ReLU\\'(x)')\n",
    "plt.title('Derivative of ReLU Activation Function')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "4a6927e2ca46ba69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sigmoid",
   "id": "41302cd9ee86e44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = torch.sigmoid(x)\n",
    "plt.plot(x.detach().numpy(), y.detach().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Sigmoid(x)')\n",
    "plt.title('Sigmoid Activation Function')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "df466e46abe62a84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x.grad.zero_()  # 清除梯度\n",
    "y.backward(torch.ones_like(x), retain_graph=True)\n",
    "plt.plot(x.detach().numpy(), x.grad.detach().numpy())\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Sigmoid\\'(x)')\n",
    "plt.title('Derivative of Sigmoid Activation Function')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "713e9d280080521c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 多层感知机",
   "id": "8eed8b2dbafb6573"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import softmax\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义多层感知机模型\n",
    "\n",
    "batch_size = 256\n",
    "train_iter,test_iter = softmax.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "num_inputs = 784  # 输入层大小\n",
    "num_outputs = 10  # 输出层大小\n",
    "num_hiddens = 256  # 隐藏层大小\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens,requires_grad=True) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens,requires_grad=True))\n",
    "W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs,requires_grad=True) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs,requires_grad=True))\n",
    "\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "def relu(_X):\n",
    "    a = torch.zeros_like(_X)\n",
    "    return torch.max(_X, a)\n",
    "\n",
    "def net(_X):\n",
    "    X = _X.reshape((-1, num_inputs))\n",
    "    H = relu(X @ W1 + b1)\n",
    "    return H @ W2 + b2\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "updater = torch.optim.SGD(params, lr=lr)\n",
    "\n",
    "sm = softmax.SoftMax(draw=True)\n",
    "sm.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)"
   ],
   "id": "b76a29687d9bf75f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP简洁实现",
   "id": "65f1a32753ab484"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import traintools\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 256), # 输入层到隐藏层\n",
    "    nn.ReLU(), # 激活函数\n",
    "    nn.Linear(256, 10) # 隐藏层到输出层\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_weights)\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "batch_size ,lr, num_epochs = 256, 0.1, 10\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train_iter, test_iter = traintools.load_data_fashion_mnist(batch_size)\n",
    "traintools.train_ch3(_net = net, _train_iter = train_iter, _test_iter=test_iter, _loss = loss, _num_epochs=num_epochs, _updater=trainer, draw=False)\n",
    "traintools.predict(net, test_iter)"
   ],
   "id": "c812016de3448ec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import traintools\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 256), # 输入层到隐藏层\n",
    "    nn.ReLU(), # 激活函数\n",
    "    nn.Linear(256, 10) # 隐藏层到输出层\n",
    ")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_weights)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "batch_size ,lr, num_epochs = 256, 0.1, 10\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "train_iter, test_iter = traintools.load_data_fashion_mnist(batch_size)\n",
    "traintools.train_model(net, train_iter, test_iter, loss, trainer, num_epochs)"
   ],
   "id": "e6091b88dffc62cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "28dbf65f19a5d81f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
